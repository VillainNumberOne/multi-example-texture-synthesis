{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "import os\n",
    "from texture_synthesis.feature_extractor import FeatureExtractor\n",
    "from texture_synthesis.function import *\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from texture_synthesis.style_features_manipulation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda\" if (torch.cuda.is_available()) else 'cpu')\n",
    "FE = FeatureExtractor().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_separation_accuracy(path1, path2, ds_size=None):\n",
    "    filenames1 = next(walk(path1), (None, None, []))[2]\n",
    "    filenames2 = next(walk(path2), (None, None, []))[2]\n",
    "\n",
    "    images1 = [Image.open(path1 + '/' + filename).convert(\"RGB\").resize((256, 256)) for filename in filenames1]\n",
    "    images2 = [Image.open(path2 + '/' + filename).convert(\"RGB\").resize((256, 256)) for filename in filenames2]\n",
    "\n",
    "    style_tensor_set1 = [FE.get_style_representation(image_to_tensor(img.resize((256, 256)), False).to(device), K=2) for img in images1]\n",
    "    style_tensor_set2 = [FE.get_style_representation(image_to_tensor(img.resize((256, 256)), False).to(device), K=2) for img in images2]\n",
    "\n",
    "    if ds_size is not None:\n",
    "        d, svm = style_attribute_extraction_svm(style_tensor_set1[:ds_size], style_tensor_set2[:ds_size], C=1)\n",
    "    else:\n",
    "        d, svm = style_attribute_extraction_svm(style_tensor_set1, style_tensor_set2, C=1)\n",
    "\n",
    "    class1 = np.logical_not(svm.predict(torch.stack(style_tensor_set1, 0).cpu().numpy())).astype(int)\n",
    "    class2 = svm.predict(torch.stack(style_tensor_set2, 0).cpu().numpy())\n",
    "\n",
    "    predictions = np.append(class1, class2)\n",
    "    print(len(predictions[predictions == 1]) / len(predictions) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All:\n",
      "100.0\n",
      "10:\n",
      "81.94444444444444\n",
      "1:\n",
      "52.77777777777778\n"
     ]
    }
   ],
   "source": [
    "path1 = 'C:/Users/М-Видео/Desktop/grad work/project/images/marble'\n",
    "path2 = 'C:/Users/М-Видео/Desktop/grad work/project/images/curly marble'\n",
    "\n",
    "print('All:')\n",
    "check_separation_accuracy(path1, path2)\n",
    "print('10:')\n",
    "check_separation_accuracy(path1, path2, 10)\n",
    "print('1:')\n",
    "check_separation_accuracy(path1, path2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All:\n",
      "100.0\n",
      "10:\n",
      "90.66666666666666\n",
      "1:\n",
      "66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "path1 = 'C:/Users/М-Видео/Desktop/grad work/project/images/grass'\n",
    "path2 = 'C:/Users/М-Видео/Desktop/grad work/project/images/grass with flowers'\n",
    "\n",
    "print('All:')\n",
    "check_separation_accuracy(path1, path2)\n",
    "print('10:')\n",
    "check_separation_accuracy(path1, path2, 10)\n",
    "print('1:')\n",
    "check_separation_accuracy(path1, path2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All:\n",
      "100.0\n",
      "10:\n",
      "93.20388349514563\n",
      "1:\n",
      "80.58252427184466\n"
     ]
    }
   ],
   "source": [
    "path1 = 'C:/Users/М-Видео/Desktop/grad work/project/images/rocks'\n",
    "path2 = 'C:/Users/М-Видео/Desktop/grad work/project/images/rocks_with_grass'\n",
    "\n",
    "print('All:')\n",
    "check_separation_accuracy(path1, path2)\n",
    "print('10:')\n",
    "check_separation_accuracy(path1, path2, 10)\n",
    "print('1:')\n",
    "check_separation_accuracy(path1, path2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "927dac595fd971fa9679342be0a4f853354c6408ed89ffe760c3ce9b26a49494"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
